{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "#Importing some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 557 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set up the ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)  # Normalize pixel values between 0 and 1 of R, G and B\n",
    "batch_size = 32  # Adjust batch size as per your requirements\n",
    "training_data = './train/' #Loading the training data directory\n",
    "train_ds = train_datagen.flow_from_directory( #normalised image. flow from directory\n",
    "       training_data, #Directory\n",
    "       target_size=(128,128), #Image size\n",
    "       batch_size=batch_size, #batch size\n",
    "       class_mode='binary'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 140 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "testing_data = './test/'\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_ds = test_datagen.flow_from_directory(\n",
    "  testing_data,\n",
    "  target_size=(128, 128),\n",
    "  batch_size=batch_size,\n",
    "  class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.layers import Flatten\n",
    "from keras.losses import BinaryCrossentropy\n",
    "model = Sequential([\n",
    "                    Conv2D(16,(3,3),activation='relu',input_shape=(128,128,3)), #16 Filters, 3x3 Filters. A filter identifies the pattern from the input, so in the first layer it will check for horizontal lines, vertical lines.etc and so I have put only 16 filters.\n",
    "                    MaxPool2D(2,2), #pooling compresses the image, (2,2) means it will take 4 pixels and return the darkest one\n",
    "                    Conv2D(32,(3,3),activation='relu'),\n",
    "                    MaxPool2D(2,2),\n",
    "                    Flatten(), #Flatten turns the 2D dimensions of an image into a 1D array for linear computation\n",
    "                    Dense(512,activation='relu'),\n",
    "                    Dense(1,activation='sigmoid')    #Sigmoid function for binary classification\n",
    "                    ])\n",
    "model.compile(optimizer='adam',loss=BinaryCrossentropy(),metrics=['accuracy']) #Adam is an optimiser like gradient descent, but it can adjust alpha automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "18/18 [==============================] - 8s 401ms/step - loss: 1.6587 - accuracy: 0.5117 - val_loss: 0.7069 - val_accuracy: 0.5000\n",
      "Epoch 2/15\n",
      "18/18 [==============================] - 7s 367ms/step - loss: 0.6850 - accuracy: 0.6014 - val_loss: 0.6763 - val_accuracy: 0.5500\n",
      "Epoch 3/15\n",
      "18/18 [==============================] - 7s 366ms/step - loss: 0.5935 - accuracy: 0.7020 - val_loss: 0.6669 - val_accuracy: 0.6357\n",
      "Epoch 4/15\n",
      "18/18 [==============================] - 6s 348ms/step - loss: 0.4961 - accuracy: 0.7899 - val_loss: 0.6591 - val_accuracy: 0.5857\n",
      "Epoch 5/15\n",
      "18/18 [==============================] - 6s 339ms/step - loss: 0.3977 - accuracy: 0.8438 - val_loss: 0.6115 - val_accuracy: 0.6429\n",
      "Epoch 6/15\n",
      "18/18 [==============================] - 6s 342ms/step - loss: 0.2859 - accuracy: 0.9300 - val_loss: 0.6300 - val_accuracy: 0.6571\n",
      "Epoch 7/15\n",
      "18/18 [==============================] - 6s 349ms/step - loss: 0.2155 - accuracy: 0.9336 - val_loss: 0.7724 - val_accuracy: 0.6143\n",
      "Epoch 8/15\n",
      "18/18 [==============================] - 6s 350ms/step - loss: 0.1346 - accuracy: 0.9623 - val_loss: 0.7852 - val_accuracy: 0.6429\n",
      "Epoch 9/15\n",
      "18/18 [==============================] - 6s 343ms/step - loss: 0.0864 - accuracy: 0.9892 - val_loss: 0.8706 - val_accuracy: 0.6429\n",
      "Epoch 10/15\n",
      "18/18 [==============================] - 6s 342ms/step - loss: 0.0563 - accuracy: 0.9964 - val_loss: 0.9221 - val_accuracy: 0.6643\n",
      "Epoch 11/15\n",
      "18/18 [==============================] - 6s 345ms/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 1.0161 - val_accuracy: 0.6357\n",
      "Epoch 12/15\n",
      "18/18 [==============================] - 6s 341ms/step - loss: 0.0226 - accuracy: 0.9982 - val_loss: 1.1340 - val_accuracy: 0.6214\n",
      "Epoch 13/15\n",
      "18/18 [==============================] - 6s 339ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 1.1486 - val_accuracy: 0.6571\n",
      "Epoch 14/15\n",
      "18/18 [==============================] - 6s 343ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 1.2320 - val_accuracy: 0.6500\n",
      "Epoch 15/15\n",
      "18/18 [==============================] - 6s 347ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.1766 - val_accuracy: 0.6857\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds,validation_data=val_ds,epochs=15) #fitting the model and training it\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Saved Models/mymodel\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Saved Models/mymodel\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./Saved Models/mymodel') #saving the model to a directory so we dont have to run the training every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('./Saved Models/mymodel') #loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "Cat\n"
     ]
    }
   ],
   "source": [
    "import cv2 #the library used for image processing\n",
    "import numpy as np\n",
    "image = cv2.imread('./bear.jpg')\n",
    "resized_image = cv2.resize(image, (128, 128))  # Resize to match the input shape of your model\n",
    "normalized_image = resized_image / 255.0  # Normalize pixel values to the range of [0, 1]\n",
    "preprocessed_image = np.expand_dims(normalized_image, axis=0)  # Add an extra dimension for batch size (assuming single image) - idk\n",
    "\n",
    "# Perform inference with your model\n",
    "predictions = model.predict(preprocessed_image)\n",
    "if predictions<0.5:\n",
    "       print(\"Cat\")\n",
    "else:\n",
    "       print(\"Dog\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
